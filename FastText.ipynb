{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bigrams(x):\n",
    "    n_grams = set(zip(*[x[i:] for i in range(2)]))\n",
    "    for n_gram in n_grams:\n",
    "        x.append(' '.join(n_gram))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "TEXT = data.Field(tokenize = 'spacy', preprocessing = generate_bigrams)\n",
    "LABEL = data.LabelField(dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_file = 'data/train-balanced-sarcasm.csv'\n",
    "data = pd.read_csv(data_file)\n",
    "data.dropna(subset=['comment'], inplace=True)\n",
    "data.head()\n",
    "data = pd.DataFrame({\"text\":data['comment'], \"label\":data['label']})\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.1)\n",
    "train, valid = train_test_split(train, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(818725, 2)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90970, 2)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101078, 2)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 399665/400000 [00:20<00:00, 18928.45it/s]"
     ]
    }
   ],
   "source": [
    "MAX_VOCAB_SIZE = 25_000\n",
    "vector = 'data/glove.840B.300d'\n",
    "\n",
    "TEXT.build_vocab(train, \n",
    "                 max_size = MAX_VOCAB_SIZE, \n",
    "                 vectors = \"glove.6B.100d\", \n",
    "                 unk_init = torch.Tensor.normal_)\n",
    "\n",
    "LABEL.build_vocab(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'BucketIterator'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-db808d6947f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5065\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5066\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5067\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5069\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'BucketIterator'"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train, valid, test), \n",
    "    batch_size = BATCH_SIZE, \n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FastText(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, output_dim, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
    "        \n",
    "        self.fc = nn.Linear(embedding_dim, output_dim)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        \n",
    "        #text = [sent len, batch size]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "                \n",
    "        #embedded = [sent len, batch size, emb dim]\n",
    "        \n",
    "        embedded = embedded.permute(1, 0, 2)\n",
    "        \n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "        pooled = F.avg_pool2d(embedded, (embedded.shape[1], 1)).squeeze(1) \n",
    "        \n",
    "        #pooled = [batch size, embedding_dim]\n",
    "                \n",
    "        return self.fc(pooled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "OUTPUT_DIM = 1\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model = FastText(INPUT_DIM, EMBEDDING_DIM, OUTPUT_DIM, PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 901 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1172e-01, -4.9659e-01,  1.6307e-01, -8.8169e-01,  5.3900e-02,\n",
       "          6.6837e-01, -5.9658e-02, -4.6750e-01, -2.1525e-01,  8.8396e-01,\n",
       "         -7.5842e-01, -3.6887e-01, -3.4239e-01, -1.4020e+00,  3.2065e-01,\n",
       "         -1.0219e+00,  7.9883e-01, -9.2288e-02, -7.0492e-01, -1.6024e+00,\n",
       "          2.8910e-01,  4.8987e-01, -3.8527e-01, -7.1203e-01, -1.7061e-01,\n",
       "         -1.4594e+00,  2.2066e-01,  2.4625e-01, -1.3248e+00,  6.9698e-01,\n",
       "         -6.6305e-01,  1.2158e+00, -1.4949e+00,  8.8096e-01, -1.1786e+00,\n",
       "         -9.3400e-01, -5.6755e-01, -2.7723e-01, -2.1834e+00,  3.6683e-01,\n",
       "          9.3803e-01,  7.8165e-03, -3.1386e-01, -1.1567e+00,  1.8409e+00,\n",
       "         -1.0174e+00,  1.2192e+00,  1.6013e-01,  1.5985e+00, -4.6861e-02,\n",
       "         -1.5270e+00, -2.0143e+00, -1.5173e+00,  3.8774e-01, -1.1849e+00,\n",
       "          6.8967e-01,  1.3232e+00,  1.8169e+00,  6.8077e-01,  7.2437e-01,\n",
       "          3.2311e-02, -1.6593e+00, -1.8773e+00,  7.3725e-01,  9.2574e-01,\n",
       "          9.2470e-01,  1.8254e-01, -7.3698e-02,  3.1468e-01, -1.0369e+00,\n",
       "          2.1004e-01,  6.1443e-01,  6.2796e-02, -3.2967e-01, -1.7970e+00,\n",
       "          8.7282e-01,  7.6696e-01, -1.1378e-01, -9.4282e-01,  7.5402e-01,\n",
       "          1.4073e-01, -6.9369e-01, -6.1589e-01, -7.2955e-01,  1.3204e+00,\n",
       "          1.5997e+00, -1.0792e+00, -3.3961e-01, -1.4538e+00, -2.6740e+00,\n",
       "          1.5984e+00,  8.0214e-01,  5.7218e-01,  6.5289e-02, -2.3459e-02,\n",
       "          8.8761e-01,  1.4689e+00,  1.2647e+00, -2.7527e-01, -1.3254e-01],\n",
       "        [-8.5549e-01, -7.2081e-01,  1.3755e+00,  9.9885e-01,  1.5495e-01,\n",
       "         -6.5262e-01,  7.1796e-01, -4.4951e-01,  6.8969e-01, -5.8444e-01,\n",
       "          9.0778e-01,  4.8482e-01, -1.5836e-01,  1.3226e+00, -2.6796e+00,\n",
       "         -1.2967e-01,  1.2907e+00,  2.6122e-01, -5.8616e-01, -1.5105e+00,\n",
       "         -1.2249e-01,  8.0783e-01, -1.1421e+00,  2.0506e+00,  5.2895e-01,\n",
       "         -5.4466e-01,  8.0967e-01,  1.1226e+00, -1.6121e+00,  4.7516e-01,\n",
       "          5.8680e-01, -2.8776e-01, -1.2777e+00, -7.4283e-01,  9.7109e-01,\n",
       "          3.5512e-01,  8.5619e-01, -3.6345e-01, -1.5518e-01, -1.2282e+00,\n",
       "         -8.0385e-01, -4.5301e-01, -2.2171e-01, -2.0901e+00, -1.2658e+00,\n",
       "         -1.8761e+00, -6.0664e-01,  7.4703e-01,  3.4744e-01,  2.8557e-01,\n",
       "         -4.9545e-02,  6.2245e-01,  1.6573e-01,  3.1583e-01,  2.4915e-01,\n",
       "         -4.9784e-01, -1.6970e-02, -2.8298e-01, -6.4459e-01, -1.9885e-02,\n",
       "          1.6222e+00,  1.4239e+00,  9.0691e-01,  7.6310e-02,  3.4223e-01,\n",
       "         -2.8727e-01, -6.7258e-01,  8.8433e-01, -6.6589e-01, -7.3347e-01,\n",
       "         -2.7599e-01,  5.5485e-01, -6.0949e-02,  2.1073e+00, -9.9300e-01,\n",
       "          1.4080e+00,  2.5969e-01,  8.0760e-01, -1.2618e+00, -7.7109e-01,\n",
       "          1.3940e+00,  6.0595e-01,  2.2088e-01, -8.2452e-01,  2.0778e-01,\n",
       "          1.1879e+00, -7.3204e-01,  1.3668e+00,  9.4616e-01,  6.1018e-01,\n",
       "         -6.2540e-01,  1.8678e+00,  6.3652e-01, -4.8517e-01, -7.1437e-01,\n",
       "         -6.0011e-02,  2.5377e-01,  8.2522e-02, -1.1314e+00,  3.9972e-01],\n",
       "        [-5.2606e-01, -6.6991e-02, -1.7351e-01, -4.0342e-01, -5.2829e-02,\n",
       "          6.7394e-01,  2.7211e-01, -3.2807e-01,  3.4143e-01, -6.7361e-02,\n",
       "          1.0542e+00, -7.6574e-01, -7.0457e-01,  2.9953e-01, -5.3097e-01,\n",
       "         -4.7552e-01,  4.3740e-01, -1.9353e-01,  2.4081e-01,  2.0918e-01,\n",
       "          3.2095e-01,  2.0893e-01,  1.2510e-01,  7.0385e-01, -4.1725e-01,\n",
       "          2.7432e-01,  4.3915e-01,  5.0170e-01,  1.7696e-01, -3.8903e-01,\n",
       "          6.1571e-01,  7.8987e-01,  6.3522e-01,  1.2491e-01,  4.8477e-01,\n",
       "         -1.7993e-01,  3.3434e-01, -2.9989e-01,  2.8422e-01,  6.8616e-01,\n",
       "         -1.2797e-02, -3.3028e-01, -6.6921e-01, -6.8731e-01, -2.3266e-01,\n",
       "          2.9715e-01, -1.2217e+00, -7.0886e-01,  7.7916e-01, -1.0730e-01,\n",
       "          8.3239e-01,  7.3632e-01,  2.9960e-02, -7.2762e-01, -7.1662e-01,\n",
       "         -1.8068e+00, -1.7706e-01,  4.5061e-01,  1.8731e+00,  5.9159e-02,\n",
       "         -7.8647e-01,  2.8095e-01, -4.4861e-01, -1.0721e+00,  2.3803e-01,\n",
       "          1.3731e-01,  8.2032e-01,  3.2646e-01,  8.9863e-01,  2.9823e-01,\n",
       "         -7.9165e-02,  7.0967e-01,  2.3473e-01, -1.4296e+00,  5.5295e-01,\n",
       "          3.4715e-01,  4.7287e-01, -3.1165e-01, -1.1327e+00, -3.9677e-01,\n",
       "          7.1413e-01, -9.4532e-01, -5.4780e-01, -8.3979e-01, -1.5342e+00,\n",
       "          1.4685e-01,  7.2147e-02, -6.9288e-01, -3.0764e-01, -5.2761e-01,\n",
       "         -9.4153e-01,  1.2313e+00,  9.9803e-01,  3.9612e-01,  3.1723e-01,\n",
       "          3.6764e-01,  8.4966e-03, -7.9123e-01,  4.7581e-02,  8.4428e-02],\n",
       "        [-4.5433e-01,  1.0234e+00,  2.4278e-02, -8.6367e-02, -6.9120e-01,\n",
       "         -1.6420e-01,  4.5726e-01,  3.0301e-01, -4.3587e-01, -3.8917e-02,\n",
       "          6.7049e-01, -1.0269e+00, -7.8994e-01,  8.2177e-01, -6.2473e-01,\n",
       "          2.1583e-01, -4.8076e-01, -2.3317e-01, -2.2187e-01, -8.2931e-02,\n",
       "          8.1076e-01, -4.8660e-01, -1.9432e-01,  9.1474e-01,  7.0682e-01,\n",
       "          2.2342e-01, -2.7363e-03,  2.2944e-01, -2.2879e-01, -6.1363e-02,\n",
       "          6.0880e-01,  9.1455e-01, -3.0613e-01,  3.1881e-01,  1.3830e-01,\n",
       "          3.4743e-01,  9.0383e-01,  4.3672e-01, -1.4860e-01,  1.3182e+00,\n",
       "          9.4098e-01, -9.0939e-01, -3.4314e-01, -1.6956e-01, -2.3347e-01,\n",
       "          3.5579e-01, -3.4606e-01,  5.1705e-02, -2.4789e-03, -1.6413e-01,\n",
       "         -6.1563e-01,  1.0916e-01,  8.9054e-01, -1.2742e-01, -2.9912e-01,\n",
       "         -9.5450e-01, -3.9694e-01,  3.8617e-01,  1.2009e+00, -1.0864e-01,\n",
       "         -6.4367e-01, -7.9820e-01, -1.3954e+00, -5.3212e-01,  9.1417e-01,\n",
       "          7.7218e-01,  2.0950e-01,  8.4292e-02,  5.2011e-01,  7.4439e-01,\n",
       "         -3.1235e-01,  2.6997e-01, -3.4347e-01, -8.3263e-01,  9.4821e-01,\n",
       "         -3.0616e-01,  8.5628e-03,  1.0950e-01, -2.3953e-01, -3.3354e-01,\n",
       "         -3.1483e-01, -1.0619e+00, -3.9500e-01, -2.7395e-01, -3.4422e-01,\n",
       "          8.8736e-01, -5.3195e-01, -1.5335e+00, -1.7591e-03, -2.6694e-01,\n",
       "         -3.7999e-01,  1.2360e-01,  3.4450e-01, -1.0445e-01,  7.7092e-01,\n",
       "         -7.5528e-02, -1.7688e-01, -4.3769e-01,  1.0169e+00, -2.6706e-01],\n",
       "        [ 1.3482e-01,  4.0224e-01, -4.2266e-01, -5.5631e-02, -5.5742e-01,\n",
       "          4.3634e-02,  4.9172e-02,  1.7382e-01, -7.4579e-01, -1.1306e-01,\n",
       "          1.9373e-01, -6.1200e-02, -4.7220e-02,  6.1629e-01,  1.6717e-01,\n",
       "          1.8415e-01,  1.7518e-01,  3.2346e-02,  8.7703e-01, -2.9756e-01,\n",
       "          4.7646e-01, -3.1404e-02,  3.6259e-01,  5.0298e-01,  2.0622e-01,\n",
       "          1.1363e+00,  3.9542e-02, -2.6770e-01,  1.5408e-01, -7.7929e-01,\n",
       "          1.1567e+00,  1.4222e+00, -2.1406e-01, -8.1809e-02,  5.3379e-01,\n",
       "          6.9233e-02,  1.8365e-01,  2.1626e-01,  1.8495e-01,  5.1840e-01,\n",
       "          1.2625e+00, -3.9466e-01,  4.4504e-03, -6.1466e-01, -8.6792e-01,\n",
       "          1.7854e-01, -6.4734e-01,  9.2421e-01,  1.0692e-01, -5.0519e-01,\n",
       "          2.7299e-01,  5.3007e-02,  3.6574e-01,  1.3988e-02, -4.1346e-01,\n",
       "         -1.7055e+00, -6.7447e-01,  6.2947e-01,  1.6272e+00,  3.7147e-01,\n",
       "         -5.2477e-01, -2.1547e-01, -5.0582e-01, -3.3827e-01,  6.3837e-01,\n",
       "          9.0879e-01,  5.1359e-01,  6.1179e-01,  4.7222e-01,  3.6789e-01,\n",
       "          3.0193e-01, -2.7832e-02, -9.4010e-01, -8.5706e-01,  6.1206e-01,\n",
       "         -1.7894e-01,  7.1163e-01,  3.5246e-01, -5.3998e-01, -4.0487e-01,\n",
       "          7.3280e-01, -1.5504e+00, -3.0557e-01, -4.2928e-01, -9.0565e-01,\n",
       "          1.5256e-01, -3.4830e-01, -7.0117e-01,  2.3922e-01,  6.9261e-01,\n",
       "          1.6522e-02,  1.0496e-01,  2.6931e-01, -3.6483e-01, -6.2628e-02,\n",
       "         -3.6180e-01, -1.4753e-01, -2.7989e-01,  2.8937e-01,  4.3783e-02],\n",
       "        [-2.7086e-01,  4.4006e-02, -2.0260e-02, -1.7395e-01,  6.4440e-01,\n",
       "          7.1213e-01,  3.5510e-01,  4.7138e-01, -2.9637e-01,  5.4427e-01,\n",
       "         -7.2294e-01, -4.7612e-03,  4.0611e-02,  4.3236e-02,  2.9729e-01,\n",
       "          1.0725e-01,  4.0156e-01, -5.3662e-01,  3.3382e-02,  6.7396e-02,\n",
       "          6.4556e-01, -8.5523e-02,  1.4103e-01,  9.4539e-02,  7.4947e-01,\n",
       "         -1.9400e-01, -6.8739e-01, -4.1741e-01, -2.2807e-01,  1.2000e-01,\n",
       "         -4.8999e-01,  8.0945e-01,  4.5138e-02, -1.1898e-01,  2.0161e-01,\n",
       "          3.9276e-01, -2.0121e-01,  3.1354e-01,  7.5304e-01,  2.5907e-01,\n",
       "         -1.1566e-01, -2.9319e-02,  9.3499e-01, -3.6067e-01,  5.2420e-01,\n",
       "          2.3706e-01,  5.2715e-01,  2.2869e-01, -5.1958e-01, -7.9349e-01,\n",
       "         -2.0368e-01, -5.0187e-01,  1.8748e-01,  9.4282e-01, -4.4834e-01,\n",
       "         -3.6792e+00,  4.4183e-02, -2.6751e-01,  2.1997e+00,  2.4100e-01,\n",
       "         -3.3425e-02,  6.9553e-01, -6.4472e-01, -7.2277e-03,  8.9575e-01,\n",
       "          2.0015e-01,  4.6493e-01,  6.1933e-01, -1.0660e-01,  8.6910e-02,\n",
       "         -4.6230e-01,  1.8262e-01, -1.5849e-01,  2.0791e-02,  1.9373e-01,\n",
       "          6.3426e-02, -3.1673e-01, -4.8177e-01, -1.3848e+00,  1.3669e-01,\n",
       "          9.6859e-01,  4.9965e-02, -2.7380e-01, -3.5686e-02, -1.0577e+00,\n",
       "         -2.4467e-01,  9.0366e-01, -1.2442e-01,  8.0776e-02, -8.3401e-01,\n",
       "          5.7201e-01,  8.8945e-02, -4.2532e-01, -1.8253e-02, -7.9995e-02,\n",
       "         -2.8581e-01, -1.0890e-02, -4.9230e-01,  6.3687e-01,  2.3642e-01],\n",
       "        [-1.0622e-01,  7.4364e-01,  1.6159e-01,  3.3806e-01, -3.9110e-01,\n",
       "          2.1238e-01,  6.1374e-01, -1.9073e-01, -6.5562e-01,  2.3641e-01,\n",
       "          1.2930e+00, -1.1731e+00, -8.2037e-01,  7.7747e-01,  6.6366e-01,\n",
       "         -4.5110e-01, -2.6503e-01,  1.5878e-01,  7.7065e-01,  4.2262e-01,\n",
       "          3.8512e-01, -5.0989e-01,  8.4023e-01,  3.5447e-01, -8.0984e-02,\n",
       "          1.0814e+00,  7.4404e-01,  5.8056e-03, -2.7944e-01,  1.6908e-01,\n",
       "          9.0519e-03,  5.3937e-01,  5.6407e-03,  6.7903e-01,  6.9463e-01,\n",
       "          3.0500e-01,  8.8817e-01,  6.2401e-01, -7.1880e-01,  4.6085e-01,\n",
       "          2.6542e-01,  8.8955e-02,  8.1105e-03, -8.8379e-01,  7.8465e-01,\n",
       "          5.4990e-01, -5.6938e-01,  4.5163e-01, -1.9679e-01, -4.1958e-01,\n",
       "          3.1280e-02,  5.2793e-01,  9.5885e-02, -1.8471e-01, -8.7934e-01,\n",
       "         -2.1017e+00, -1.1786e+00, -8.2476e-02,  1.4561e+00,  1.0154e+00,\n",
       "         -1.9729e-01, -5.2219e-01, -2.4407e-01,  1.3045e-01,  1.1269e+00,\n",
       "          9.2459e-01,  7.6288e-01,  9.0351e-01, -1.2638e-01,  1.9230e-01,\n",
       "         -6.6376e-01,  2.6918e-02, -2.0428e-02, -1.4488e-01,  3.0672e-01,\n",
       "         -1.8459e-01, -5.3877e-01, -2.9509e-02, -2.4551e-01, -9.7987e-01,\n",
       "         -2.9538e-01, -3.6265e-01,  3.8115e-02, -9.6799e-01, -5.2508e-01,\n",
       "          1.6333e-01, -1.0366e+00, -7.5630e-01, -1.1441e-01,  8.1822e-01,\n",
       "         -9.6350e-01,  4.8354e-01,  2.1052e-01,  2.9345e-01, -1.1342e-01,\n",
       "          5.0442e-01,  2.7102e-03, -5.3448e-01, -3.9819e-01, -1.3595e-01],\n",
       "        [-6.7212e-01,  1.1458e+00,  1.2519e-01,  1.9952e-01, -3.9315e-01,\n",
       "          3.3718e-01,  5.2010e-01, -1.5572e-01, -3.3985e-01,  2.2342e-01,\n",
       "          9.5812e-01, -8.0619e-01,  4.6807e-01, -5.6215e-01,  4.4596e-01,\n",
       "          2.4495e-01, -8.7304e-02,  1.3327e+00, -7.1722e-01,  4.5057e-01,\n",
       "         -1.5811e-01, -9.9305e-02, -1.3445e-01,  1.1753e+00,  5.8250e-01,\n",
       "          9.9031e-01,  1.0862e+00, -2.3455e-01,  4.0067e-01, -2.9061e-02,\n",
       "          8.9291e-01,  8.9762e-02, -5.3367e-01,  1.1238e+00,  4.9020e-01,\n",
       "          2.0711e-01,  3.0766e-01,  2.5482e-01,  7.5024e-01,  6.8642e-01,\n",
       "          2.8429e-01, -1.0786e+00,  1.8878e-01, -6.9493e-01, -4.6758e-01,\n",
       "         -1.0616e-01, -6.9971e-01,  1.3130e-01, -4.3326e-02,  4.3160e-01,\n",
       "         -4.8832e-02,  6.2417e-01,  5.3646e-01,  9.8370e-01, -5.0914e-01,\n",
       "         -2.0855e+00, -2.3882e-01,  4.7396e-01,  8.2951e-01,  3.4906e-01,\n",
       "         -4.6740e-01,  3.9270e-01, -3.7313e-01,  2.8256e-02,  7.1730e-01,\n",
       "          8.1749e-01, -3.4132e-01,  6.3578e-01,  5.8216e-01,  5.1497e-01,\n",
       "         -5.1773e-01, -6.0168e-02, -3.9114e-01,  1.0411e+00,  1.1063e+00,\n",
       "         -5.4461e-01,  1.6112e-01,  6.4514e-02, -9.0730e-01, -6.8471e-01,\n",
       "         -5.3346e-02, -5.9435e-01, -6.2462e-02,  1.4322e-01, -5.1916e-01,\n",
       "          7.0420e-01,  5.0722e-01, -1.1287e+00,  3.8835e-01,  2.9836e-01,\n",
       "         -4.2530e-01,  1.3999e+00,  3.7627e-01,  1.7920e-01,  7.3920e-02,\n",
       "         -7.2332e-02, -1.3556e-01, -5.7917e-01,  4.1294e-01, -7.1662e-01]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "model = model.to('cpu')\n",
    "criterion = criterion.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(batch.text).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.label)\n",
    "        \n",
    "        acc = binary_accuracy(predictions, batch.label)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model(batch.text).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch.label)\n",
    "            \n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_iterator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-d75d1578428d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_iterator' is not defined"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 5\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut3-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('tut3-model.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|█████████▉| 399665/400000 [00:39<00:00, 18928.45it/s]"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "def predict_sentiment(model, sentence):\n",
    "    model.eval()\n",
    "    tokenized = generate_bigrams([tok.text for tok in nlp.tokenizer(sentence)])\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    prediction = torch.sigmoid(model(tensor))\n",
    "    return prediction.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
